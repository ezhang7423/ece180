{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of ECE180-S21-HW3-part2.ipynb","provenance":[{"file_id":"1Lioj2lzFAcPxdj4Y8xIfpz5nD1NM0Hf9","timestamp":1619050337033},{"file_id":"1oBoIWXa3ASLsqHfr7PfX94isDBe1FPM9","timestamp":1618536307133}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python386jvsc74a57bd082f71d0f31804d59dc54bb35da862ad8f684505c18de90fa2ae8b754eb12f5f2","display_name":"Python 3.8.6 64-bit"},"language_info":{"name":"python","version":"3.8.6"},"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"cells":[{"cell_type":"markdown","metadata":{"id":"6X9SbpLPgRjc"},"source":["### **HW3 Part 2: Due Date: Friday, April 23, 5PM PDT, on Gradescope.**\n"]},{"cell_type":"markdown","metadata":{"id":"ogSkkESOdnMM"},"source":["# Submission instructions\n","\n","1. Copy this notebook into your own Google drive with its original name (for example, you can copy this notebook to a folder named `ECE180` that you create in your Google Drive).\n","2. Work on your own copy and after you are done, make sure all your code has executed and output of the code (if any) is visible below each code block for full credit. You are given skeleton code for Problem 1 and 2 below.\n","3. To submit to gradescope, download this notebook as a pdf (using `nbconvert` - instructions mentioned below and summarized in point 4, 5 here) after executing all code blocks and rename the pdf to ECE180-S21-HW3-part2-FirstName-LastName-PermNumber.pdf and then submit. **Note**: **When submitting your pdf to gradescope, please indicate the pages where your answers are located.**\n","4. Note: the default location for Google drive after you mount it (see below for how to mounting) `/content/drive/MyDrive`.\n","5. Say that the location of this notebook on your google drive is in a folder `ECE180`. Then, the full path for the notebook in Google Colab with its original name would be: `/content/drive/MyDrive/ECE180/ECE180-S21-HW3-part2.ipynb`. Towards the end of this notebook, you will see the command to convert this notebook to pdf, which would be saved as /content/drive/MyDrive/ECE180/ECE180-S21-HW3-part2.pdf. This is the pdf you will rename (point 3) and submit."]},{"cell_type":"markdown","metadata":{"id":"IzH71E5Sc8S_"},"source":["# Linear Regression using Gradient Descent\n","\n","In this programming exercise, you will implement linear regression using gradient descent (without deep learning libraries such as Tensorflow or Pytorch).\n","You will submit this part of HW3 through a Google Colab notebook. This notebook provides a skeleton of how to organize your code adn responses to the questions asked. **Report all your answers to the questions below in your copy of this notebook and submit your copy as a separate pdf on Gradescope.**\n","\n","\n","**Dataset.** You will be using the housing dataset for this task. The input data is a 2-dimensional feature vector containing square feet and number of bedrooms and the expected output is the house price.\n","This housing dataset is located in the file: housing\\_prices.txt in the HW3 folder in Gauchospace or it can also be found here: https://drive.google.com/file/d/1fFhs_7axS56NOyFEY-KWjmX3Zh5rzRLs/view?usp=sharing.\n","Each row in housing\\_prices.txt contains the square footage, number of bedrooms and selling price separated by commas.\n","\n","**Model.** The linear regression model we want to train is: $y = m1\\cdot x1 + m2\\cdot x2 + m0$. Here, $y$ is the housing price, $x1$ is the square footage, $x2$ is the number of bedrooms. The parameters of the model are $m1,m2,m0$.\n","\n","**Train / Test split.** Choose the last 10 rows as your testing set and do NOT train on these samples.\n","\n","Respond to each of the questionS (a) through (f) below."]},{"cell_type":"markdown","metadata":{"id":"MP-Msko4csER"},"source":["**(a) Visualize your data.**"]},{"cell_type":"code","metadata":{"id":"jWdFw2gFcpwn"},"source":["## visualization code here\n","\n","## Insert your code here\n","# Load the dataset\n","\n","# Plot your data\n","# Refer to this material on how to generate 3d plots using matplotlib: https://jakevdp.github.io/PythonDataScienceHandbook/04.12-three-dimensional-plotting.html\n","# Don't forget to separate part of the data to be used only for testing\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ng5oh8qOcyiL"},"source":["**(b) Using mean-squared error as the loss function, derive the update rule for parameters. Mention the update rule in your report.**"]},{"cell_type":"markdown","metadata":{"id":"zxVFCt45eirx"},"source":["*Your answer here:*"]},{"cell_type":"markdown","metadata":{"id":"Ej83Z8-Ie7gy"},"source":["**(c) Using the update rule, implement and train the linear regression model. You can train the model for $10$ epochs, with a learning rate of $10^{-7}$. Show the plot of the average train and test loss as a function of the number of epochs (you can use one plot for both train and test, use a different line style and specify a legend).**"]},{"cell_type":"code","metadata":{"id":"7us8xo48fbmC"},"source":["\n","# Using the update rule you derived, train the linear regression model, show the code and final plot\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mT5RFlwOfc1Q"},"source":["**(d) Data Normalization: When input data or features differ by orders of magnitude, first performing feature scaling will give better results. Lets define the data normalization as follows:**\n","1.   **Subtract the mean value of each feature from the dataset,**\n","2.   **Divide the features obtained from (i) by their respective standard deviations.**\n","\n","**What are the results of training with normalized data and a learning rate of $0.1$. Show the plot of the average train and test loss as a function of the number of epochs (plot train and test on a single plot as done in (c)).**\n"]},{"cell_type":"code","metadata":{"id":"Lrp4GuPfa2lk"},"source":["\n","# Next, let's explore the effect of normalizing the data before training\n","# For this step, calculate the mean and standard deviation of each feature\n","# Then, subtract the mean from the feature values and divide by the standard deviation\n","\n","# Train your model again using the normalized data\n","# You can define your training code on a function so that you can reuse it for this step\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FYZ-9z7Qa2El"},"source":["**(e) Compare the results of with-normalization against without-normalization and Comment on them.**\n"]},{"cell_type":"markdown","metadata":{"id":"mgN5H0xjgNSQ"},"source":["*Your answer here*"]},{"cell_type":"markdown","metadata":{"id":"JhJEPgJcgQFW"},"source":["**(f) Train the model using different learning rate values: $0.01,0.05,0.1,5,10$ WITH data normalization. For each learning rate, show the plot of the average train and test loss as a function of the number of epochs (plot train and test on a single plot as done in (c)).**"]},{"cell_type":"code","metadata":{"id":"2lKOzUkRgX1Q"},"source":["## code to train with 5 different learning rates."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d_6TmzX-5Bty"},"source":["---\n","# Save out the notebook\n","If you saved this notebook into the folder `ECE180` in google drive with original name, then run the following command (otherwise, adjust the path to the notebook and its name according to how you saved it). The saved out PDF will show up in the same directory as your copy of this notebook. Rename the pdf as mentioned in submission instructions and submit it to gradescope. The conversion will not work correctly if preliminary step 2 and 3 were not completed without errors. Be sure to check that the converted pdf in your Google Drive is fully rendered with all your responses."]}]}