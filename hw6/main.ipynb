{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python","version":"3.8.6"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Go1vxz_oxqZ9","executionInfo":{"status":"ok","timestamp":1621464825995,"user_tz":420,"elapsed":627,"user":{"displayName":"Eddie Zhang","photoUrl":"","userId":"02258624714158002324"}}},"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplt as plt\n","torch.manual_seed(4)\n","np.random.seed(4)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxQYAYqhxqaD","executionInfo":{"status":"ok","timestamp":1621464825995,"user_tz":420,"elapsed":623,"user":{"displayName":"Eddie Zhang","photoUrl":"","userId":"02258624714158002324"}}},"source":["BATCH_SIZE = 128\n","NUM_ITERS = int(2e4)\n","CRITERION = nn.CrossEntropyLoss()  \n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oyArAn3SxqaD","executionInfo":{"status":"ok","timestamp":1621464827874,"user_tz":420,"elapsed":2498,"user":{"displayName":"Eddie Zhang","photoUrl":"","userId":"02258624714158002324"}},"outputId":"bb95771d-5503-4b5b-fbaa-fa0e36da8cbd"},"source":["\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True,  transform=transform)\n","\n","\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n","                                        shuffle=True, num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n","                                        shuffle=False, num_workers=2)\n","\n","EPOCHS = int(NUM_ITERS / (len(trainset) / BATCH_SIZE))\n","\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(DEVICE)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","cpu\n"]}]},{"cell_type":"code","metadata":{"id":"JKd7Cc0JxqaE","executionInfo":{"status":"ok","timestamp":1621464827874,"user_tz":420,"elapsed":2492,"user":{"displayName":"Eddie Zhang","photoUrl":"","userId":"02258624714158002324"}}},"source":["\n","# Block\n","\n","class ConvBlock(nn.Module):\n","\n","    def __init__(self, stride=1, padding=1, batch_norm=False):\n","        super().__init__()\n","        self.batch_norm = batch_norm\n","        \n","        self.conv1 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=stride, padding=padding)\n","\n","        if batch_norm:\n","            self.bn1 = nn.BatchNorm2d(8)\n","\n","        self.relu1 = nn.ReLU()        \n","\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=stride, padding=padding)\n","\n","        if batch_norm:\n","            self.bn2 = nn.BatchNorm2d(8)\n","\n","        self.relu2 = nn.ReLU()       \n","\n","         \n","\n","\n","    def forward(self, x):\n","\n","        out = self.conv1(x)\n","\n","        if self.batch_norm:\n","            out = self.bn1(out)\n","\n","        out = self.relu1(out)\n","\n","        out = self.conv2(x)\n","\n","        if self.batch_norm:\n","            out = self.bn2(out)\n","\n","        out = self.relu2(out)\n","\n","        return out\n","\n","# Model\n","class CNNModel(nn.Module):\n","    def __init__(self, batch_norm=False, N=10):\n","\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5, stride=1, padding=0)\n","        # Size: 28 x 28\n","\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=5, stride=1, padding=0)\n","        # Size: 24 x 24\n","\n","        # Dynamic block num\n","        # self.blocks = nn.Sequential(*[ConvBlock(batch_norm=batch_norm) for _ in range(N)])\n","        # Size: 24 x 24\n","\n","        self.conv3 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, stride=2, padding=0)                    \n","        # Size: 11 X 11\n","\n","        self.fc1 = nn.Linear(11 * 11 * 4, 100, bias=True) \n","        self.relu1 = nn.ReLU()\n","        self.fc2 = nn.Linear(100, 10) \n","\n","\n","    def forward(self, x):\n","\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        \n","        # out = self.blocks(out)         # How is the shape the same after this???\n","        out = self.conv3(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc1(out)\n","        out = self.relu1(out)\n","        out = self.fc2(out)\n","\n","        return out"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4_F9ETdxqaF","executionInfo":{"status":"ok","timestamp":1621464827874,"user_tz":420,"elapsed":2482,"user":{"displayName":"Eddie Zhang","photoUrl":"","userId":"02258624714158002324"}}},"source":["\n","def calc_accuracy(model, train=False): # add train param to calculate accuracy on both train and test\n","    # Calculate Accuracy         \n","    correct = 0\n","    total = 0\n","    \n","    d_loader = train_loader if train else test_loader\n","    # Iterate through test dataset\n","    for images, labels in d_loader:\n","        # Load images\n","        images, labels = images.to(DEVICE), labels.to(DEVICE)        \n","\n","        # Forward pass only to get logits/output\n","        outputs = model(images)\n","\n","        # Get predictions from the maximum value\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        # Total number of labels\n","        total += labels.size(0)\n","\n","        # Total correct predictions\n","        correct += (predicted == labels).sum()\n","\n","    return 100 * correct / total\n","\n","def train(model): \n","    print(f'Training for {EPOCHS} epochs')\n","    optimizer = torch.optim.SGD(model.parameters(), lr=.01)  \n","    accuracy = {'train': [], 'test': []}\n","\n","    for epoch in range(EPOCHS):    \n","        for i, (images, labels) in enumerate(train_loader): \n","            # This will load batch_size amount of samples\n","            images, labels = images.to(DEVICE), labels.to(DEVICE)         \n","            \n","\n","            # Clear gradients w.r.t. parameters\n","            optimizer.zero_grad()\n","\n","            # Forward pass to get output/logits\n","            outputs = model(images)\n","\n","            # Calculate Loss: softmax --> cross entropy loss\n","            loss = CRITERION(outputs, labels)\n","\n","            # Getting gradients w.r.t. parameters\n","            loss.backward()\n","\n","            # Updating parameters\n","            optimizer.step()\n","\n","        train_accuracy = calc_accuracy(model, train=True) # abstract accuracy function away\n","        test_accuracy = calc_accuracy(model) # abstract accuracy function away\n","        # Print Loss\n","        print('Epoch: {} Loss: {}. Train Accuracy: {}, Test Accuracy: {}'.format(epoch, loss.item(), train_accuracy, test_accuracy))\n","\n","        accuracy['train'].append(train_accuracy.item())\n","        accuracy['test'].append(test_accuracy.item())\n","        \n","    return pd.DataFrame(accuracy)"],"execution_count":6,"outputs":[]},{"source":["## a) Plot Train and Test accuracy"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H41-2RjcxqaF","outputId":"b5443a7c-6374-4b22-fe09-534d0a0477b4"},"source":["\n","no_batch_norm = CNNModel().to(DEVICE)\n","nbn_history = train(no_batch_norm)\n","nbn_history.plot(y=['train', 'test'], use_index=True, xlabel='Epoch no.', ylabel='Accuracy (%)')    "],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'CNNModel' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4aeb71888a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mno_batch_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_batch_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'CNNModel' is not defined"]}]},{"cell_type":"code","metadata":{"id":"CXtUVBUFy1ga"},"source":["batch_norm = CNNModel(batch_norm=True).to(DEVICE)\n","bn_history = train(batch_norm)\n","bn_history.plot(y=['train', 'test'], use_index=True, xlabel='Epoch no.', ylabel='Accuracy (%)')    "],"execution_count":null,"outputs":[]},{"source":["## b) Optimal value of N w/o batch normalization"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nbn_models = []\n","nbn_histories = []\n","for test_n in range(2, N):\n","    if test_n % 2 == 0: # if it's even\n","        model = CNNModel(N=test_n).to(DEVICE)\n","        nbn_models.append(model)\n","        history = train(model)\n","        nbn_histories.append(history)\n","        history.plot(y=['train', 'test'], use_index=True, xlabel='Epoch no.', ylabel='Accuracy (%)')    \n","        plt.title(f'Accuracy plot with {test_n} blocks')\n","    \n"]},{"source":["### Analysis\n","\n","From these experiments, we can see that _ is the optimal number of blocks when using a CNN without batch normalization. This was a little surprising to me, as I thought that increasing the depth of the model would directly correlate to better performance. However, we see that this isn't really the case."],"cell_type":"markdown","metadata":{}},{"source":["## c) Plot 2 misclassified and 2 correctly classified samples for each class"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}